{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_SEED = 7532\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(GLOBAL_SEED)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(GLOBAL_SEED)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization, Dense, Dropout, Conv2D, Flatten, MaxPool2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('train_set_metadata.csv')\n",
    "valid_set = pd.read_csv('valid_set_metadata.csv')\n",
    "test_set = pd.read_csv('test_set_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the main constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (256, 384, 3)\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the VGG16 model without the top part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 384, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 384, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 384, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 192, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 192, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 192, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 96, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 96, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 96, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 48, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 12, 512)        0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_top(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    dropout_rate = 0.25\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(rate=dropout_rate, seed=GLOBAL_SEED))\n",
    "    model.add(Dense(units=1024, activation='relu'))\n",
    "    model.add(Dropout(rate=dropout_rate, seed=GLOBAL_SEED))\n",
    "    model.add(Dense(units=256, activation='relu'))\n",
    "    model.add(Dropout(rate=dropout_rate, seed=GLOBAL_SEED))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach the model top to the VGG16 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 384, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 384, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 384, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 192, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 192, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 192, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 96, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 96, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 96, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 48, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 12, 512)        0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 5)                 50596357  \n",
      "=================================================================\n",
      "Total params: 65,311,045\n",
      "Trainable params: 50,596,357\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_top = create_model_top(vgg16_model.outputs[0].get_shape().as_list()[1:])\n",
    "model = Model(inputs=vgg16_model.inputs, outputs=model_top(vgg16_model.outputs[0]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the appropriate layers are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the f1 metric to be used during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1_Metric(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        predict = np.round(np.asarray(self.model.predict(self.validation_data[0])))\n",
    "        targ = self.validation_data[1]\n",
    "\n",
    "        self.f1_scores.append(f1_score(targ, predict, average='weighted'))\n",
    "        \n",
    "        print(f' val_f1: {self.f1_scores[-1]}')\n",
    "        \n",
    "        return\n",
    "    \n",
    "f1_metric = F1_Metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the class weights to be used during model training in order to fight the class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.589811320754717,\n",
       " 1: 1.0717714285714286,\n",
       " 2: 1.3650655021834062,\n",
       " 3: 1.5028846153846154,\n",
       " 4: 1.0271631982475355}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_values = train_set['category'].values - 1\n",
    "\n",
    "classes = np.unique(class_values)\n",
    "weights = compute_class_weight('balanced', np.unique(class_values), class_values)\n",
    "\n",
    "class_weights = dict(zip(classes, weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model utilizing Adam optimizer, learning rate reduction on plateau, class weights and data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 157s - loss: 6.0217 - val_loss: 1.9538\n",
      " val_f1: 0.7867220992517062\n",
      "Epoch 2/100\n",
      " - 123s - loss: 3.1127 - val_loss: 1.4969\n",
      " val_f1: 0.8093275017072427\n",
      "Epoch 3/100\n",
      " - 123s - loss: 2.2001 - val_loss: 1.1362\n",
      " val_f1: 0.8038195868418624\n",
      "Epoch 4/100\n",
      " - 123s - loss: 1.5973 - val_loss: 0.6016\n",
      " val_f1: 0.8333116403876368\n",
      "Epoch 5/100\n",
      " - 123s - loss: 1.1584 - val_loss: 0.4450\n",
      " val_f1: 0.8243335125863693\n",
      "Epoch 6/100\n",
      " - 123s - loss: 0.8943 - val_loss: 0.4133\n",
      " val_f1: 0.8401069292156482\n",
      "Epoch 7/100\n",
      " - 124s - loss: 0.8075 - val_loss: 0.4064\n",
      " val_f1: 0.8418190571308317\n",
      "Epoch 8/100\n",
      " - 125s - loss: 0.6824 - val_loss: 0.3863\n",
      " val_f1: 0.8527781338419472\n",
      "Epoch 9/100\n",
      " - 124s - loss: 0.6636 - val_loss: 0.4361\n",
      " val_f1: 0.8242042283800883\n",
      "Epoch 10/100\n",
      " - 123s - loss: 0.6153 - val_loss: 0.3384\n",
      " val_f1: 0.8774729098883726\n",
      "Epoch 11/100\n",
      " - 124s - loss: 0.6054 - val_loss: 0.3517\n",
      " val_f1: 0.8688256518439901\n",
      "Epoch 12/100\n",
      " - 123s - loss: 0.5760 - val_loss: 0.3414\n",
      " val_f1: 0.8663448186890806\n",
      "Epoch 13/100\n",
      " - 123s - loss: 0.5297 - val_loss: 0.3462\n",
      " val_f1: 0.8774584695221554\n",
      "Epoch 14/100\n",
      " - 124s - loss: 0.4910 - val_loss: 0.3272\n",
      " val_f1: 0.8830626610178951\n",
      "Epoch 15/100\n",
      " - 123s - loss: 0.5060 - val_loss: 0.3305\n",
      " val_f1: 0.8809136403347327\n",
      "Epoch 16/100\n",
      " - 124s - loss: 0.5023 - val_loss: 0.3214\n",
      " val_f1: 0.8777965571431345\n",
      "Epoch 17/100\n",
      " - 124s - loss: 0.4710 - val_loss: 0.3385\n",
      " val_f1: 0.8643837943818183\n",
      "Epoch 18/100\n",
      " - 123s - loss: 0.4455 - val_loss: 0.3309\n",
      " val_f1: 0.872808394383494\n",
      "Epoch 19/100\n",
      " - 124s - loss: 0.4312 - val_loss: 0.2993\n",
      " val_f1: 0.8871173967800559\n",
      "Epoch 20/100\n",
      " - 123s - loss: 0.4148 - val_loss: 0.3118\n",
      " val_f1: 0.8820814996813119\n",
      "Epoch 21/100\n",
      " - 123s - loss: 0.4212 - val_loss: 0.3068\n",
      " val_f1: 0.885608901810356\n",
      "Epoch 22/100\n",
      " - 123s - loss: 0.4037 - val_loss: 0.3179\n",
      " val_f1: 0.8897170795288672\n",
      "Epoch 23/100\n",
      " - 123s - loss: 0.3836 - val_loss: 0.3121\n",
      " val_f1: 0.8903643696275768\n",
      "Epoch 24/100\n",
      " - 123s - loss: 0.3899 - val_loss: 0.2902\n",
      " val_f1: 0.890196741293003\n",
      "Epoch 25/100\n",
      " - 123s - loss: 0.3700 - val_loss: 0.2972\n",
      " val_f1: 0.8948677311890634\n",
      "Epoch 26/100\n",
      " - 123s - loss: 0.3618 - val_loss: 0.2992\n",
      " val_f1: 0.8903188220752138\n",
      "Epoch 27/100\n",
      " - 123s - loss: 0.3654 - val_loss: 0.3182\n",
      " val_f1: 0.8755399927392385\n",
      "Epoch 28/100\n",
      " - 123s - loss: 0.3486 - val_loss: 0.2738\n",
      " val_f1: 0.8938038995035567\n",
      "Epoch 29/100\n",
      " - 123s - loss: 0.3495 - val_loss: 0.3138\n",
      " val_f1: 0.8863489508680088\n",
      "Epoch 30/100\n",
      " - 123s - loss: 0.3486 - val_loss: 0.3021\n",
      " val_f1: 0.8942644137812544\n",
      "Epoch 31/100\n",
      " - 124s - loss: 0.3489 - val_loss: 0.2874\n",
      " val_f1: 0.8986622455272214\n",
      "Epoch 32/100\n",
      " - 123s - loss: 0.3253 - val_loss: 0.2978\n",
      " val_f1: 0.8934566748973615\n",
      "Epoch 33/100\n",
      " - 123s - loss: 0.3439 - val_loss: 0.2993\n",
      " val_f1: 0.8871894178151081\n",
      "Epoch 34/100\n",
      " - 123s - loss: 0.3164 - val_loss: 0.3074\n",
      " val_f1: 0.8957620290271606\n",
      "Epoch 35/100\n",
      " - 124s - loss: 0.3084 - val_loss: 0.2874\n",
      " val_f1: 0.8974806295267262\n",
      "Epoch 36/100\n",
      " - 123s - loss: 0.3017 - val_loss: 0.3049\n",
      " val_f1: 0.8970643860903752\n",
      "Epoch 37/100\n",
      " - 123s - loss: 0.2955 - val_loss: 0.2848\n",
      " val_f1: 0.8997719856581016\n",
      "Epoch 38/100\n",
      " - 123s - loss: 0.2908 - val_loss: 0.2786\n",
      " val_f1: 0.9019581529118844\n",
      "Epoch 39/100\n",
      " - 123s - loss: 0.2606 - val_loss: 0.2854\n",
      " val_f1: 0.8989670089853615\n",
      "Epoch 40/100\n",
      " - 123s - loss: 0.2704 - val_loss: 0.2799\n",
      " val_f1: 0.9029920509547457\n",
      "Epoch 41/100\n",
      " - 123s - loss: 0.2645 - val_loss: 0.2840\n",
      " val_f1: 0.8957950624654613\n",
      "Epoch 42/100\n",
      " - 123s - loss: 0.2511 - val_loss: 0.2615\n",
      " val_f1: 0.9049851192002749\n",
      "Epoch 43/100\n",
      " - 123s - loss: 0.2490 - val_loss: 0.2708\n",
      " val_f1: 0.9026714267559777\n",
      "Epoch 44/100\n",
      " - 123s - loss: 0.2444 - val_loss: 0.2756\n",
      " val_f1: 0.9045770084983049\n",
      "Epoch 45/100\n",
      " - 123s - loss: 0.2278 - val_loss: 0.2765\n",
      " val_f1: 0.9031941594590177\n",
      "Epoch 46/100\n",
      " - 123s - loss: 0.2309 - val_loss: 0.2684\n",
      " val_f1: 0.9061481876351363\n",
      "Epoch 47/100\n",
      " - 123s - loss: 0.2429 - val_loss: 0.2813\n",
      " val_f1: 0.9040543926191558\n",
      "Epoch 48/100\n",
      " - 123s - loss: 0.2488 - val_loss: 0.2844\n",
      " val_f1: 0.9027363995027232\n",
      "Epoch 49/100\n",
      " - 123s - loss: 0.2300 - val_loss: 0.2707\n",
      " val_f1: 0.9059923911785452\n",
      "Epoch 50/100\n",
      " - 124s - loss: 0.2181 - val_loss: 0.2710\n",
      " val_f1: 0.9085512294522077\n",
      "Epoch 51/100\n",
      " - 123s - loss: 0.2204 - val_loss: 0.2716\n",
      " val_f1: 0.9063773199141095\n",
      "Epoch 52/100\n",
      " - 123s - loss: 0.2090 - val_loss: 0.2751\n",
      " val_f1: 0.9040349766394609\n",
      "Epoch 53/100\n",
      " - 123s - loss: 0.2156 - val_loss: 0.2698\n",
      " val_f1: 0.9041225685126983\n",
      "Epoch 54/100\n",
      " - 123s - loss: 0.2158 - val_loss: 0.2677\n",
      " val_f1: 0.9078718501810078\n",
      "Epoch 55/100\n",
      " - 123s - loss: 0.2170 - val_loss: 0.2702\n",
      " val_f1: 0.9069804981493225\n",
      "Epoch 56/100\n",
      " - 124s - loss: 0.2118 - val_loss: 0.2703\n",
      " val_f1: 0.906613035915976\n",
      "Epoch 57/100\n",
      " - 123s - loss: 0.2101 - val_loss: 0.2706\n",
      " val_f1: 0.9072807537225274\n",
      "Epoch 58/100\n",
      " - 123s - loss: 0.2108 - val_loss: 0.2702\n",
      " val_f1: 0.9066891217087157\n",
      "Epoch 59/100\n",
      " - 123s - loss: 0.2099 - val_loss: 0.2669\n",
      " val_f1: 0.9052982257126384\n",
      "Epoch 60/100\n",
      " - 123s - loss: 0.1927 - val_loss: 0.2692\n",
      " val_f1: 0.9057503310048732\n",
      "Epoch 61/100\n",
      " - 125s - loss: 0.2062 - val_loss: 0.2699\n",
      " val_f1: 0.9092724421966646\n",
      "Epoch 62/100\n",
      " - 123s - loss: 0.2131 - val_loss: 0.2692\n",
      " val_f1: 0.9086259379245523\n",
      "Epoch 63/100\n",
      " - 123s - loss: 0.1986 - val_loss: 0.2714\n",
      " val_f1: 0.9074989938333189\n",
      "Epoch 64/100\n",
      " - 124s - loss: 0.2002 - val_loss: 0.2730\n",
      " val_f1: 0.9071283766621454\n",
      "Epoch 65/100\n",
      " - 123s - loss: 0.2107 - val_loss: 0.2719\n",
      " val_f1: 0.9074954307182185\n",
      "Epoch 66/100\n",
      " - 123s - loss: 0.1937 - val_loss: 0.2716\n",
      " val_f1: 0.9087447649596949\n",
      "Epoch 67/100\n",
      " - 123s - loss: 0.1959 - val_loss: 0.2709\n",
      " val_f1: 0.9081240864748922\n",
      "Epoch 68/100\n",
      " - 123s - loss: 0.1862 - val_loss: 0.2711\n",
      " val_f1: 0.9086883756891168\n",
      "Epoch 69/100\n",
      " - 123s - loss: 0.1952 - val_loss: 0.2702\n",
      " val_f1: 0.9084569520549273\n",
      "Epoch 70/100\n",
      " - 123s - loss: 0.2069 - val_loss: 0.2693\n",
      " val_f1: 0.9079581472753769\n",
      "Epoch 71/100\n",
      " - 123s - loss: 0.2129 - val_loss: 0.2690\n",
      " val_f1: 0.9083276230148088\n",
      "Epoch 72/100\n",
      " - 123s - loss: 0.2056 - val_loss: 0.2678\n",
      " val_f1: 0.9086991694087847\n",
      "Epoch 73/100\n",
      " - 123s - loss: 0.1871 - val_loss: 0.2679\n",
      " val_f1: 0.9089526305786272\n",
      "Epoch 74/100\n",
      " - 123s - loss: 0.2015 - val_loss: 0.2676\n",
      " val_f1: 0.9086445368122731\n",
      "Epoch 75/100\n",
      " - 123s - loss: 0.1991 - val_loss: 0.2680\n",
      " val_f1: 0.9083310624329264\n",
      "Epoch 76/100\n",
      " - 123s - loss: 0.1982 - val_loss: 0.2682\n",
      " val_f1: 0.9086725287586601\n",
      "Epoch 77/100\n",
      " - 124s - loss: 0.2098 - val_loss: 0.2682\n",
      " val_f1: 0.9088515459428042\n",
      "Epoch 78/100\n",
      " - 123s - loss: 0.2124 - val_loss: 0.2680\n",
      " val_f1: 0.9089328475040185\n",
      "Epoch 79/100\n",
      " - 123s - loss: 0.2013 - val_loss: 0.2681\n",
      " val_f1: 0.9089328475040185\n",
      "Epoch 80/100\n",
      " - 123s - loss: 0.1928 - val_loss: 0.2683\n",
      " val_f1: 0.9088997989812375\n",
      "Epoch 81/100\n",
      " - 123s - loss: 0.1861 - val_loss: 0.2685\n",
      " val_f1: 0.908590558924646\n",
      "Epoch 82/100\n",
      " - 123s - loss: 0.1860 - val_loss: 0.2684\n",
      " val_f1: 0.9088515459428042\n",
      "Epoch 83/100\n",
      " - 123s - loss: 0.1949 - val_loss: 0.2682\n",
      " val_f1: 0.9088412742357022\n",
      "Epoch 84/100\n",
      " - 123s - loss: 0.1954 - val_loss: 0.2680\n",
      " val_f1: 0.909154766767784\n",
      "Epoch 85/100\n",
      " - 123s - loss: 0.1943 - val_loss: 0.2680\n",
      " val_f1: 0.9094626505083379\n",
      "Epoch 86/100\n",
      " - 123s - loss: 0.1874 - val_loss: 0.2680\n",
      " val_f1: 0.909154766767784\n",
      "Epoch 87/100\n",
      " - 124s - loss: 0.1844 - val_loss: 0.2680\n",
      " val_f1: 0.909154766767784\n",
      "Epoch 88/100\n",
      " - 126s - loss: 0.1944 - val_loss: 0.2681\n",
      " val_f1: 0.9094737872786829\n",
      "Epoch 89/100\n",
      " - 124s - loss: 0.1912 - val_loss: 0.2681\n",
      " val_f1: 0.9094737872786829\n",
      "Epoch 90/100\n",
      " - 124s - loss: 0.1908 - val_loss: 0.2681\n",
      " val_f1: 0.9094737872786829\n",
      "Epoch 91/100\n",
      " - 124s - loss: 0.1945 - val_loss: 0.2681\n",
      " val_f1: 0.9094737872786829\n",
      "Epoch 92/100\n",
      " - 123s - loss: 0.1961 - val_loss: 0.2680\n",
      " val_f1: 0.9094737872786829\n",
      "Epoch 93/100\n",
      " - 124s - loss: 0.1975 - val_loss: 0.2680\n",
      " val_f1: 0.9092119515222542\n",
      "Epoch 94/100\n",
      " - 124s - loss: 0.1878 - val_loss: 0.2680\n",
      " val_f1: 0.9092119515222542\n",
      "Epoch 95/100\n",
      " - 123s - loss: 0.1894 - val_loss: 0.2680\n",
      " val_f1: 0.9092119515222542\n",
      "Epoch 96/100\n",
      " - 124s - loss: 0.1954 - val_loss: 0.2680\n",
      " val_f1: 0.9092119515222542\n",
      "Epoch 97/100\n",
      " - 124s - loss: 0.2130 - val_loss: 0.2680\n",
      " val_f1: 0.9092119515222542\n",
      "Epoch 98/100\n",
      " - 123s - loss: 0.1965 - val_loss: 0.2680\n",
      " val_f1: 0.9092119515222542\n",
      "Epoch 99/100\n",
      " - 124s - loss: 0.1867 - val_loss: 0.2680\n",
      " val_f1: 0.9092119515222542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      " - 123s - loss: 0.2005 - val_loss: 0.2680\n",
      " val_f1: 0.9092119515222542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e81101cf60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the training and validation data\n",
    "X_train = np.load('train_set_hmgd_arr_256_384_VGG16.npy')\n",
    "y_train = to_categorical(train_set['category'].values - 1)\n",
    "\n",
    "X_valid = np.load('valid_set_hmgd_arr_256_384_VGG16.npy')\n",
    "y_valid = to_categorical(valid_set['category'].values - 1)\n",
    "\n",
    "\n",
    "# Create and compile the model\n",
    "adam = Adam(lr=LEARNING_RATE)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "# Initialize callbacks\n",
    "checkpoint = ModelCheckpoint('model_006_epoch_{epoch:03d}.hdf5', monitor='val_loss', \n",
    "                             save_best_only=False, save_weights_only=False)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6)\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=12)    \n",
    "callback_list = [f1_metric, checkpoint, lr_reduction]#, early_stopping]\n",
    "\n",
    "\n",
    "# data augmentation\n",
    "data_gen = ImageDataGenerator(rotation_range=20, \n",
    "                              width_shift_range=0.2, \n",
    "                              height_shift_range=0.2, \n",
    "                              horizontal_flip=True)\n",
    "\n",
    "steps_per_epoch = int(len(X_train)) / BATCH_SIZE\n",
    "\n",
    "model.fit_generator(data_gen.flow(X_train, y_train, batch_size=BATCH_SIZE), \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    epochs=N_EPOCHS,\n",
    "                    callbacks=callback_list,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    class_weight=class_weights,\n",
    "                    workers=4, \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up memory\n",
    "del X_train\n",
    "del X_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the test data as well as the best model with respect to the f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('test_set_hmgd_arr_256_384_VGG16.npy')\n",
    "model = load_model('model_006_epoch_088.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predictions and prepare the submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 4, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_classes = model.predict(X_test).argmax(axis=-1) + 1\n",
    "test_pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission = sample_submission.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    905\n",
       "5    541\n",
       "2    492\n",
       "3    391\n",
       "4    351\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['category'] = test_pred_classes\n",
    "submission['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007700.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011369.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1051155.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1062001.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1069397.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  category\n",
       "0  1007700.jpg         4\n",
       "1  1011369.jpg         4\n",
       "2  1051155.jpg         4\n",
       "3  1062001.jpg         2\n",
       "4  1069397.jpg         4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('model_006_submission_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                      Epoch 88\n",
    "# Validation score:  0.9094737873\n",
    "# Leaderboard score: 0.9155052841"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
